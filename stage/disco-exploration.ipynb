{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc096823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327af64",
   "metadata": {},
   "source": [
    "## Tinkering with envs, rendering and ui control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import ObservationWrapper\n",
    "\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8802d",
   "metadata": {},
   "source": [
    "human mode rendered that measures the wall-time it took to draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def render(env):\n",
    "    \"\"\"Render and return the time (in ms.) it took, or\n",
    "    zero if the rendered is closed.\n",
    "    \"\"\"\n",
    "    mark = time.monotonic()\n",
    "    if not env.render(mode='human'):\n",
    "        return 0.\n",
    "\n",
    "    return time.monotonic() - mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48368cb8",
   "metadata": {},
   "source": [
    "Simple Keyboard control for pyglet windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b597d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyglet.window import key, Window\n",
    "\n",
    "class SimpleUIControl:\n",
    "    \"\"\"A bare-bones keyboard event handler for pyglet UI.\"\"\"\n",
    "\n",
    "    action, pause, waiting, dream = None, False, False, False\n",
    "    def __init__(self, keymap):\n",
    "        self.KEYMAP = keymap\n",
    "\n",
    "    def on_key_press(self, symbol, modifiers):\n",
    "        if symbol == key.SPACE:\n",
    "            self.pause = not self.pause\n",
    "            return\n",
    "\n",
    "        if symbol == key.P:\n",
    "            self.dream = not self.dream\n",
    "            return\n",
    "\n",
    "        if symbol in self.KEYMAP and not self.waiting:\n",
    "            self.action, self.waiting = symbol, True\n",
    "            return\n",
    "\n",
    "    def on_key_release(self, symbol, modifiers):\n",
    "        if symbol in self.KEYMAP and self.waiting:\n",
    "            self.action, self.waiting = None, False\n",
    "            return\n",
    "    \n",
    "    def register(self, window):\n",
    "        assert isinstance(window, Window)\n",
    "\n",
    "        window.push_handlers(\n",
    "            self.on_key_press, \n",
    "            self.on_key_release,\n",
    "        )\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0ba82",
   "metadata": {},
   "source": [
    "### Random Disco Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_discomaze.ext import ExploreRandomDiscoMaze\n",
    "\n",
    "class DiscoMazeFactory:\n",
    "    KEYMAP = dict(zip(\n",
    "        [None, key.E, key.A, key.S, key.D, key.W],\n",
    "        ['stay', 'stay', 'west', 'south', 'east', 'north'],\n",
    "    ))\n",
    "\n",
    "    def __call__(self, seed=None):\n",
    "        env = ExploreRandomDiscoMaze(\n",
    "            field=(2, 2), n_colors=5, generator=seed)\n",
    "        env.KEYMAP = self.KEYMAP\n",
    "\n",
    "        return env\n",
    "\n",
    "factory = DiscoMazeFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032db336",
   "metadata": {},
   "source": [
    "### Atari"
   ]
  },
  {
   "cell_type": "raw",
   "id": "652ddb11",
   "metadata": {},
   "source": [
    "import rlplay.utils.integration.gym  # gym renderer hotfix\n",
    "\n",
    "from rlplay.utils.wrappers import AtariObservation\n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces import Box\n",
    "\n",
    "\n",
    "class FakeChannel(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = Box(\n",
    "            low=self.observation(env.observation_space.low),\n",
    "            high=self.observation(env.observation_space.high),\n",
    "            dtype=env.observation_space.dtype)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return observation[..., None]\n",
    "\n",
    "class SpaceInvadersFactory:\n",
    "    KEYMAP = dict(zip(\n",
    "        [None, key.W, key.D, key.A, key.Q, key.E],\n",
    "        ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE'],\n",
    "    ))\n",
    "\n",
    "    def __call__(self, seed=None):\n",
    "        # have to generate a seed from the sequence manually, since gym is OLD!\n",
    "        seed = int(default_rng(seed).integers(numpy.iinfo(numpy.int32).max))\n",
    "\n",
    "        env = gym.make('SpaceInvaders-v0')\n",
    "        env.named_actions = {n: j for j, n in enumerate(self.KEYMAP.values())}\n",
    "        env.KEYMAP = self.KEYMAP\n",
    "\n",
    "        env = FakeChannel(AtariObservation(env, shape=(50, 50)))\n",
    "        env.seed(seed)\n",
    "\n",
    "        return env\n",
    "\n",
    "factory = SpaceInvadersFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe568e83",
   "metadata": {},
   "source": [
    "### Gym-Minigrid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "091a6fb1",
   "metadata": {},
   "source": [
    "import gym_minigrid\n",
    "import rlplay.utils.integration.gym_minigrid  # minigrid renderer hotfix\n",
    "\n",
    "from gym_minigrid.wrappers import FullyObsWrapper, RGBImgObsWrapper\n",
    "\n",
    "class ImageObsOnly(ObservationWrapper):\n",
    "    def observation(self, observation):\n",
    "        return observation['image']\n",
    "\n",
    "class MinigridFactory:\n",
    "    KEYMAP = dict(zip(\n",
    "        [key.A, key.D, key.W],\n",
    "        ['<', '^', '>'],\n",
    "    ))\n",
    "\n",
    "    def __call__(self, seed=None):\n",
    "        # have to generate a seed from the sequence manually, since gym is OLD!\n",
    "        seed = int(default_rng(seed).integers(numpy.iinfo(numpy.int32).max))\n",
    "\n",
    "        env = gym.make(\"MiniGrid-Dynamic-Obstacles-8x8-v0\")\n",
    "        env.KEYMAP = self.KEYMAP\n",
    "        env.named_actions = {n: j for j, n in enumerate(self.KEYMAP.values())}\n",
    "        \n",
    "        env = ImageObsOnly(RGBImgObsWrapper(FullyObsWrapper(env)))\n",
    "        \n",
    "        env.seed(seed)\n",
    "\n",
    "        return env\n",
    "\n",
    "factory = MinigridFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64308969",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89121766",
   "metadata": {},
   "source": [
    "## Random Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36ec37",
   "metadata": {},
   "source": [
    "collect data for the VAE by random exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c94797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlplay.engine.rollout import same, multi, single\n",
    "from rlplay.engine.core import BaseActorModule\n",
    "\n",
    "class RandomActor(BaseActorModule):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        stepno,\n",
    "        obs,\n",
    "        act,\n",
    "        rew,\n",
    "        fin,\n",
    "        *,\n",
    "        hx=None,\n",
    "        virtual=False,\n",
    "    ):\n",
    "        if not virtual:\n",
    "            act = torch.randint_like(act, self.action_space.n)\n",
    "        return act, (), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = factory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfd480",
   "metadata": {},
   "source": [
    "**FKRY**\n",
    "\n",
    "a code block in `shared.py#L119-122` (either `.empty`, if\n",
    "replaced with `.zeros`, or `.copy_`) may freeze due to waiting\n",
    "on a mutex inside torch's `parallel_for`. This can be avoided\n",
    "if we set `torch.set_num_threads(1)` in the main process.\n",
    "\n",
    "```python\n",
    "torch.set_num_threads(1)  # in case of unexpected hangups\n",
    "```\n",
    "* maybe the funky behavior is due to the `fork` method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rndgen = same.rollout(\n",
    "#     [factory(_) for _ in range(12)],\n",
    "#     RandomActor(env),\n",
    "#     n_steps=1,\n",
    "# )\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "rndgen = multi.rollout(\n",
    "    factory,\n",
    "    RandomActor(env),\n",
    "    n_steps=8,      # n_steps=8,\n",
    "    n_per_actor=5,  # minigrid: 2, discomaze: 5\n",
    "    n_buffers=12,   # n_buffers=12,\n",
    "    n_actors=4,     # n_actors=3,\n",
    "    n_per_batch=2,  # minigrid: 1, discomaze: 2\n",
    "    start_method='fork',\n",
    "    entropy=None,\n",
    ")\n",
    "\n",
    "# T, B = 8, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(obs):\n",
    "    # `.div` makes a copy for sure\n",
    "    return obs.permute(0, 1, 4, 2, 3).div(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cba8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ref = []\n",
    "for frag, j in zip(rndgen, tqdm.tqdm(range(5))):\n",
    "    obs = to_tensor(frag.state.obs)\n",
    "    ref.append(obs.flatten(0, 1))\n",
    "\n",
    "ref = torch.cat(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ref.std(0).permute(1, 2, 0))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1525b93",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed70ae8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Conv2d, Embedding, Linear, Sequential, LeakyReLU, Flatten, GRU\n",
    "from torch.nn import ConvTranspose2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12629cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "def init_random_eye_embed(layer):\n",
    "    assert isinstance(layer, torch.nn.Embedding)  # guard\n",
    "    n_embed, n_dim = layer.weight.shape\n",
    "    layer.weight.data.normal_(std=1e-1)\n",
    "    init.eye_(layer.weight[:, :n_embed])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5010afa",
   "metadata": {},
   "source": [
    "Modules for vbayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65096f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU\n",
    "from rlplay.zoo.models.vae import Reshape\n",
    "\n",
    "from rlplay.zoo.models.vae import AsIndependentGaussian\n",
    "from rlplay.zoo.models.vae import AsIndependentBernoulli\n",
    "from rlplay.zoo.models.vae import AsIndependentContinuousBernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8470d",
   "metadata": {},
   "source": [
    "How to force the variance of the Gaussian decoder to one?\n",
    "```python\n",
    "dec = AsIndependentGaussian(\n",
    "    ...,\n",
    "    fn_loc=torch.sigmoid,\n",
    "    fn_scale = torch.ones_like,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70027d98",
   "metadata": {},
   "source": [
    "### DiscoMaze vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46065f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = 128\n",
    "\n",
    "enc = AsIndependentGaussian(\n",
    "    Sequential(\n",
    "        Conv2d(3, 64, 3),\n",
    "        ReLU(),\n",
    "        Conv2d(64, 128, 3),\n",
    "        ReLU(),\n",
    "        Flatten(-3, -1),\n",
    "        Linear(128, 2 * n_latent)\n",
    "    ),\n",
    "    n_dim_in=3,\n",
    "    n_dim_out=1,\n",
    ")\n",
    "\n",
    "dec = AsIndependentContinuousBernoulli(\n",
    "    Sequential(\n",
    "        Linear(n_latent, 128),\n",
    "        ReLU(),\n",
    "        Reshape((128, 1, 1), start_dim=-1, end_dim=-1),\n",
    "        ConvTranspose2d(128, 64, 3),\n",
    "        ReLU(),\n",
    "        ConvTranspose2d(64, 3, 3),\n",
    "    ),\n",
    "    n_dim_in=1,\n",
    "    n_dim_out=3,\n",
    "    # validate_args=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5e24ba",
   "metadata": {},
   "source": [
    "### Atari VAE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b099d340",
   "metadata": {},
   "source": [
    "n_latent = 64\n",
    "\n",
    "enc = AsIndependentGaussian(\n",
    "    Sequential(\n",
    "        Conv2d(1, 32, 4, stride=2),\n",
    "        ReLU(),\n",
    "        Conv2d(32, 64, 4, stride=2),\n",
    "        ReLU(),\n",
    "        Flatten(-3, -1),\n",
    "        Linear(7744, 2 * n_latent)\n",
    "    ),\n",
    "    n_dim_in=3,\n",
    "    n_dim_out=1,\n",
    ")\n",
    "\n",
    "dec = AsIndependentBernoulli(\n",
    "    Sequential(\n",
    "        Linear(n_latent, 7744),\n",
    "        ReLU(),\n",
    "        Reshape((64, 11, 11), start_dim=-1, end_dim=-1),\n",
    "#         ConvTranspose2d(64, 128, 11),\n",
    "#         ReLU(),\n",
    "        ConvTranspose2d(64, 64, 4, stride=2),\n",
    "        ReLU(),\n",
    "        ConvTranspose2d(64, 1, 4, stride=2)\n",
    "    ),\n",
    "    n_dim_in=1,\n",
    "    n_dim_out=3,\n",
    "    validate_args=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d015a9c",
   "metadata": {},
   "source": [
    "### minigrid VAE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b683cee6",
   "metadata": {},
   "source": [
    "n_latent = 32\n",
    "\n",
    "enc = AsIndependentGaussian(\n",
    "    Sequential(\n",
    "        Conv2d(3, 16, 5, stride=1),\n",
    "        ReLU(),\n",
    "        Conv2d(16, 32, 5, stride=1),\n",
    "        ReLU(),\n",
    "        Flatten(start_dim=-3, end_dim=-1),\n",
    "        Linear(32 * 56 * 56, 2 * n_latent),\n",
    "    ),\n",
    "    n_dim_in=3,\n",
    "    n_dim_out=1,\n",
    ")\n",
    "\n",
    "dec = AsIndependentBernoulli(\n",
    "    Sequential(\n",
    "        Linear(n_latent, 32 * 56 * 56),\n",
    "        ReLU(),\n",
    "        Reshape(32, 56, 56, start_dim=-1, end_dim=-1),\n",
    "        ConvTranspose2d(32, 16, 5),\n",
    "        ReLU(),\n",
    "        ConvTranspose2d(16, 3, 5),\n",
    "    ),\n",
    "    n_dim_in=1,\n",
    "    n_dim_out=3,\n",
    "    validate_args=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "396a4b46",
   "metadata": {},
   "source": [
    "class Dyn(torch.nn.Module):\n",
    "    def __init__(self, n_blocks=1, n_hid=32, n_act=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = torch.nn.Embedding(\n",
    "            n_act,\n",
    "            4 * n_act,\n",
    "            max_norm=1.,\n",
    "        )\n",
    "        init_random_eye_embed(self.embed)\n",
    "\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            Sequential(\n",
    "                Linear(n_hid + 4 * n_act, 4 * n_hid),\n",
    "                ReLU(),\n",
    "                Linear(4 * n_hid, 4 * n_hid),\n",
    "                ReLU(),\n",
    "                Linear(4 * n_hid, n_hid),\n",
    "            ) for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "        self.final = Linear(n_hid, 2 * n_hid)\n",
    "    \n",
    "    def forward(self, z, act):\n",
    "        emb = self.embed(act)\n",
    "        for blk in self.blocks:\n",
    "            z = z + blk(torch.cat([z, emb], dim=-1))\n",
    "        return self.final(z)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63f2e579",
   "metadata": {},
   "source": [
    "class Dyn(torch.nn.Module):\n",
    "    def __init__(self, n_blocks=1, n_hid=32, n_act=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = torch.nn.Embedding(\n",
    "            n_act,\n",
    "            4 * n_act,\n",
    "            max_norm=1.,\n",
    "        )\n",
    "        init_random_eye_embed(self.embed)\n",
    "\n",
    "        self.transform = Sequential(\n",
    "            Linear(n_hid + 4 * n_act, 4 * n_hid),\n",
    "            ReLU(),\n",
    "            Linear(4 * n_hid, 4 * n_hid),\n",
    "            torch.nn.Tanh(),\n",
    "            Linear(4 * n_hid, 2 * n_hid),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, act):\n",
    "        return self.transform(torch.cat([\n",
    "            z, self.embed(act)\n",
    "        ], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c55fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynGRU(torch.nn.Module):\n",
    "    def __init__(self, n_blocks=None, n_hid=32, n_act=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = torch.nn.Embedding(\n",
    "            n_act,\n",
    "            4 * n_act,\n",
    "            max_norm=1.,\n",
    "        )\n",
    "        init_random_eye_embed(self.embed)\n",
    "\n",
    "        self.transform = torch.nn.GRUCell(\n",
    "            4 * n_act,\n",
    "            2 * n_hid,\n",
    "        )\n",
    "        self.output = Sequential(\n",
    "            torch.nn.Tanh(),\n",
    "            Linear(2 * n_hid, 2 * n_hid),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, act):\n",
    "        hid = torch.cat([z]*2, dim=-1)\n",
    "        return self.output(self.transform(self.embed(act), hid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f26cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn = AsIndependentGaussian(\n",
    "    DynGRU(\n",
    "        n_blocks=1,\n",
    "        n_hid=n_latent,\n",
    "        n_act=n_actions,\n",
    "    ),\n",
    "    n_dim_in=1,\n",
    "    n_dim_out=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea627ba",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2674d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ea666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyr import apply, suply, xgetitem\n",
    "\n",
    "def timeshift(state, *, shift=1):\n",
    "    \"\"\"Get current and shifted slices of nested objects.\"\"\"\n",
    "    # use `xgetitem` to let None through\n",
    "    # XXX `curr[t]` = (x_t, a_{t-1}, r_t, d_t), t=0..T-H\n",
    "    curr = suply(xgetitem, state, index=slice(None, -shift))\n",
    "\n",
    "    # XXX `next[t]` = (x_{t+H}, a_{t+H-1}, r_{t+H}, d_{t+H}), t=0..T-H\n",
    "    next = suply(xgetitem, state, index=slice(shift, None))\n",
    "\n",
    "    return curr, next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27987c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fragment):\n",
    "    st, sn = timeshift(fragment.state)\n",
    "    return suply(\n",
    "        torch.flatten,\n",
    "        (\n",
    "            to_tensor(st.obs),\n",
    "            sn.act.clone(),  # force a clone, since __getitem__ returns a view!\n",
    "            to_tensor(sn.obs),\n",
    "        ),\n",
    "        start_dim=0,\n",
    "        end_dim=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaac96d",
   "metadata": {},
   "source": [
    "prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def buffered_shuffle(buffer, *obs, n_capacity=None):\n",
    "    n_capacity = n_capacity or len(buffer)\n",
    "\n",
    "    evicted = []\n",
    "    for x in zip(*obs):\n",
    "        if len(buffer) >= n_capacity:\n",
    "            ix = random.randint(0, n_capacity - 1)\n",
    "            evicted.append(buffer[ix])\n",
    "            buffer[ix] = x\n",
    "\n",
    "        else:\n",
    "            buffer.append(x)\n",
    "    \n",
    "#     if not evicted:\n",
    "#         random.shuffle(buffer)\n",
    "#         evicted = buffer[:]\n",
    "#         buffer.clear()\n",
    "\n",
    "    return evicted\n",
    "\n",
    "\n",
    "# experience replay buffer\n",
    "buffer, n_capacity = [], 512\n",
    "for frag in rndgen:\n",
    "    # flatten the fragment's temporal and batch dims\n",
    "    st, act, sn = get_data(frag)\n",
    "\n",
    "    batch = buffered_shuffle(\n",
    "        buffer,\n",
    "        st, act, sn,\n",
    "        n_capacity=n_capacity,\n",
    "    )\n",
    "\n",
    "    # abort on full buffer\n",
    "    if batch:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a53e63",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efde9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "from rlplay.zoo.models.vae import vbayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "jn, j0, j1 = 10000, 500, 3000\n",
    "e0, e1, lo = 1500, 9500, 1e-2\n",
    "\n",
    "# jn, j0, j1 = 1000, 50, 300\n",
    "# e0, e1, lo = 150, 950, 1e-2\n",
    "# jn, j0, j1 = 5000, 250, 1500\n",
    "# e0, e1, lo = 750, 4750, 1e-2\n",
    "\n",
    "optim = torch.optim.Adam([\n",
    "    *enc.parameters(),\n",
    "    *dyn.parameters(),\n",
    "    *dec.parameters(),\n",
    "], lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# sched = None\n",
    "\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim, lr_lambda=lambda e: min(1., max(lo, (e1 - e) / (e1 - e0))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41827bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "from torch.distributions import kl_divergence as KL\n",
    "\n",
    "losses = []\n",
    "for frag, j in zip(rndgen, tqdm.tqdm(range(jn))):\n",
    "    st, act, sn = default_collate(\n",
    "        buffered_shuffle(buffer, *get_data(frag))\n",
    "    )\n",
    "\n",
    "    # learn vae\n",
    "    # XXX it is possible that torch optimizes away mul-by-zero autograd paths\n",
    "    beta = min(1., max(0., (j - j0) / (j1 - j0)))\n",
    "    C = 0.25\n",
    "\n",
    "    if False:\n",
    "        # classic VAE neg-elbo via one-sample SGVB\n",
    "        pi = enc.prior(st)  # \\pi = p(z)\n",
    "        qt = enc(st)        # q_t = q(z_t \\mid x_t)\n",
    "        zt = qt.rsample()   #   draw > z_t \\sim q_t\n",
    "        pt = dec(zt)        # p_t = p(x_t \\mid z_t)\n",
    "      \n",
    "        llt = pt.log_prob(st).mean()\n",
    "        klt = KL(qt, pi).mean()\n",
    "        llh = 0.\n",
    "        klh = 0.\n",
    "#         loss = vbayes(\n",
    "#             enc,\n",
    "#             dec,\n",
    "#             st,\n",
    "#             beta=beta,\n",
    "#             n_draws=1,\n",
    "#             iwae=False,\n",
    "#         )\n",
    "\n",
    "    else:\n",
    "        # neg-ELBO from Embed2Control\n",
    "        # XXX don't forget that it is __R__sample, you eed-yot!\n",
    "        # XXX see eq. (8) of Watter at al. (2015) for `qh`\n",
    "        pi = enc.prior(st)  # \\pi = p(z)\n",
    "        qt = enc(st)        # q_t = q(z_t \\mid x_t)\n",
    "        zt = qt.rsample()   # draw -->> z_t \\sim q_t\n",
    "        pt = dec(zt)        # p_t = p(x_t \\mid z_t)\n",
    "        # XXX zt.detach() below?\n",
    "        qh = dyn(zt, act)   # \\hat{q}_{t+1} = r(z_{t+1} \\mid z_t, a_t)\n",
    "        zh = qh.rsample()   # draw -->> \\hat{z}_{t+1} \\sim \\hat{q}_{t+1}\n",
    "        ph = dec(zh)        # \\hat{p}_{t+1} = p(x_t \\mid \\hat{z}_{t+1})\n",
    "        qn = enc(sn)        # q_{t+1} = q(z_{t+1} \\mid x_{t+1})\n",
    "\n",
    "        # \\log p_t(x_t) + \\log \\hat{p}_{t+1}(x_{t+1})\n",
    "        llt = pt.log_prob(st).mean()\n",
    "        llh = ph.log_prob(sn).mean()\n",
    "\n",
    "        # KL(q_t \\| \\pi) + \\lambda KL(\\hat{q}_{t+1} \\| q_{t+1})\n",
    "        klt = KL(qt, pi).mean()\n",
    "        klh = KL(qh, qn).mean()\n",
    "\n",
    "    loss = beta * (klt + C * klh) - llh - llt\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loglik = dec(enc(ref).sample()).log_prob(ref).mean()\n",
    "\n",
    "    losses.append((\n",
    "        -float(loss),\n",
    "        float(loglik),\n",
    "        float(llt),\n",
    "        float(llh),\n",
    "        float(klt),\n",
    "        float(klh),\n",
    "    ))\n",
    "    \n",
    "    if sched is not None:\n",
    "        sched.step()\n",
    "    \n",
    "    if isnan(float(loss)):\n",
    "        raise FloatingPointError"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6100944c",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8870234",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, llt, llh, klt, klh = zip(*losses)\n",
    "plt.plot(llt)\n",
    "plt.plot(llh)\n",
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa82ec",
   "metadata": {},
   "source": [
    "reload an older model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "228c9cde",
   "metadata": {},
   "source": [
    "state_dict = torch.load(\n",
    "    './minigrid-gud-enc-dec-dyn.pk', torch.device('cpu')\n",
    ")\n",
    "\n",
    "torch.nn.ModuleDict(dict(\n",
    "    enc=enc, dec=dec, dyn=dyn\n",
    ")).load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037670df",
   "metadata": {},
   "source": [
    "display the reference set reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlplay.utils.plotting.grid import make_grid as _make_grid\n",
    "\n",
    "def make_grid(tensor):\n",
    "    return _make_grid(\n",
    "        tensor,\n",
    "        aspect=(1, 1),\n",
    "        pixel=(1, 1),\n",
    "        pad=(0, 0),\n",
    "        normalize=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rec = dec(enc(ref).sample()).mean\n",
    "\n",
    "err = F.mse_loss(rec, ref, reduction='none').mean(1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=240)\n",
    "ax.imshow(make_grid(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84300fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(3, 5), dpi=240, sharey=True, sharex=True)\n",
    "ax[0].imshow(ref[3].permute(1, 2, 0))\n",
    "ax[1].imshow(rec[3].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65ef48",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44fed1",
   "metadata": {},
   "source": [
    "A gui-play loop, with extra reconstruction renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20eaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_iv0(obs, sample=True):\n",
    "    # get the initial internal vector\n",
    "    x = torch.tensor(obs).permute(2, 0, 1).div(255)\n",
    "    q = enc(x.unsqueeze(0))\n",
    "    return q.sample() if sample else q.mean\n",
    "\n",
    "@torch.no_grad()\n",
    "def next_iv(zed, act, sample=True):\n",
    "    # get the next internal vector via one-step dynamics\n",
    "    r = dyn(zed, act)\n",
    "    return r.sample() if sample else r.mean\n",
    "\n",
    "def play(env, ctrl, viewer=None, sample=True):\n",
    "    obs, fin, act = env.reset(), False, env.action_space.sample()\n",
    "\n",
    "    z0 = get_iv0(obs, sample=sample)\n",
    "    zt = next_iv(z0, torch.tensor([act]), sample=sample)\n",
    "    while not fin:\n",
    "        if viewer is not None:\n",
    "            with torch.no_grad():\n",
    "                x = torch.tensor(obs).permute(2, 0, 1).div(255)\n",
    "                hat_x = dec(z0).mean\n",
    "                rec = hat_x[0].permute(1, 2, 0).mul(255).byte().squeeze(-1)\n",
    "            \n",
    "                xp1 = dec(zt).mean\n",
    "                nxt = xp1[0].permute(1, 2, 0).mul(255).byte().squeeze(-1)\n",
    "            \n",
    "            if isinstance(viewer, MultiViewer):\n",
    "                viewer['curr'].imshow(rec.numpy())\n",
    "                viewer['next'].imshow(nxt.numpy())\n",
    "            else:\n",
    "                viewer.imshow(rec.numpy())\n",
    "\n",
    "        if ctrl.action is not None:  # makes atari turn-based!\n",
    "            act = env.named_actions[env.KEYMAP[ctrl.action]]\n",
    "            ctrl.action = None\n",
    "\n",
    "            if not ctrl.dream:\n",
    "                obs, rew, fin, info = env.step(act)\n",
    "                # reset the latent dynamics\n",
    "                zt = z0 = get_iv0(obs, sample=sample)\n",
    "            # advance the latent dynamics state\n",
    "            zt = next_iv(zt, torch.tensor([act]), sample=sample)\n",
    "\n",
    "        if fin:  # pause on termination\n",
    "            ctrl.pause = True\n",
    "\n",
    "        # rendering and UI event loop\n",
    "        while render(env) > 0:\n",
    "            time.sleep(0.04)\n",
    "            if not ctrl.pause:\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967322b",
   "metadata": {},
   "source": [
    "The loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gym_discomaze\n",
    "env = factory(123)\n",
    "\n",
    "ctrl = SimpleUIControl(env.KEYMAP)\n",
    "\n",
    "render(env)  # sets up the viewer gui, so that the next line works\n",
    "ctrl.register(env.unwrapped.viewer.window)\n",
    "\n",
    "from rlplay.utils.plotting import ImageViewer, MultiViewer\n",
    "\n",
    "with MultiViewer(scale=(5, 5)) as mvw:\n",
    "    vw1 = mvw.get('curr', r'\\hat{s}_t')\n",
    "    vw2 = mvw.get('next', r'\\hat{s}_{t+1}')\n",
    "    while play(env, ctrl, mvw):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while env.render('human'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "673997fe",
   "metadata": {},
   "source": [
    "torch.save(\n",
    "    torch.nn.ModuleDict(dict(\n",
    "        enc=enc, dec=dec, dyn=dyn\n",
    "    )).state_dict(),\n",
    "    './minigrid-gud-enc-dec-dyn.pk',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986477ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "1a12b112",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44b740",
   "metadata": {},
   "source": [
    "```python\n",
    "start = torch.arange(1., 5.)\n",
    "end = torch.empty(4).fill_(10)\n",
    "torch.lerp(start, end, torch.full_like(start, 0.5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdbdee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{H}\n",
    "    \\mathcal{N}_d(\\mu, \\Sigma)\n",
    "        = \\frac12 \\log \\det 2 \\pi e \\Sigma\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e5525",
   "metadata": {},
   "source": [
    "$$\n",
    "\\operatorname{KL}\\bigl(\n",
    "    \\mathcal{N}_d(\\mu_0, \\Sigma_0)\n",
    "    \\| \\mathcal{N}_d(\\mu_1, \\Sigma_1)\n",
    "\\bigr)\n",
    "    = \\frac12 \\biggl\\{\n",
    "        \\operatorname{tr}\\Bigl(\n",
    "            \\Sigma_1^{-1} \\Sigma_0\n",
    "            + \\Sigma_1^{-1} ( \\mu_1 - \\mu_0) ( \\mu_1 - \\mu_0)^\\top\n",
    "        \\Bigr)\n",
    "        + \\log \\frac{ \\det 2 \\pi \\Sigma_1 }{ \\det 2 \\pi e \\Sigma_0 }\n",
    "    \\biggr\\},\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec2f38",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)\n",
    "    = \\frac1{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "    \\,. $$\n",
    "\n",
    "$X \\sim p$ and $Y = g(X)$, then\n",
    "$$\n",
    "p_Y(y)\n",
    "    = \\frac{d}{dy} \\mathbb{P}(Y\\leq y)\n",
    "    = f(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y)\n",
    "    = \\frac1{g'(x)} p_X(x) \\big\\vert_{x=g^{-1}(y)}\n",
    "    \\,, $$\n",
    "thus\n",
    "$$\n",
    "\\log p_Y(y)\n",
    "    = \\frac{d}{dy} \\mathbb{P}(Y\\leq y)\n",
    "    = f(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y)\n",
    "    = \\log p_X(g^{-1}(y)) - \\log{g'(g^{-1}(y))}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594c43a",
   "metadata": {},
   "source": [
    "If $X \\sim p$ and $Y = g(X)$, then\n",
    "$$\n",
    "p_Y(y) dy\n",
    "    = f(g^{-1}(y)) \\bigl\\lvert \\det J_{g^{-1}}(y) \\bigr\\rvert dy\n",
    "    % = f(g^{-1}(y)) \\bigl\\lvert \\det (J_g(g^{-1}(y)))^{-1} \\bigr\\rvert dy\n",
    "    = f(g^{-1}(y)) \\bigl\\lvert \\det J_g(g^{-1}(y)) \\bigr\\rvert^{-1} dy\n",
    "    \\,, $$\n",
    "thus\n",
    "$$\n",
    "\\log p_Y(y)\n",
    "    = \\frac{d}{dy} \\mathbb{P}(Y\\leq y)\n",
    "    = f(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y)\n",
    "    = \\log p_X(g^{-1}(y)) - \\log{g'(g^{-1}(y))}\n",
    "    \\,. $$\n",
    "\n",
    "Hence\n",
    "$$\n",
    "\\int_A p_X(x) dx\n",
    "    = \\mathbb{P}(X \\in A)\n",
    "    = \\mathbb{P}(Y \\in g(A))\n",
    "    = \\int_{g(A)} p_Y(y) dy\n",
    "    = \\int_A p_Y(g(x)) \\bigl\\lvert \\det J_g(x) \\bigr\\rvert dx\n",
    "    \\,. $$\n",
    "\n",
    "almost surely\n",
    "$$\n",
    "p_X(x)\n",
    "    = p_Y(g(x)) \\bigl\\lvert \\det J_g(x) \\bigr\\rvert\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c1ebb",
   "metadata": {},
   "source": [
    "if $x_k = f_k(x_{k-1})$ and $f_k$ is a diffeomorphism on the support, then\n",
    "(for $g=f_k^{-1}$)\n",
    "$$\n",
    "p_k(x_k)\n",
    "    = p_{k-1}(x_{k-1}) \\,\n",
    "    \\biggl\\lvert\n",
    "        \\det \\frac{\\partial f_k(x_{k-1})}{\\partial x_{k-1}}\n",
    "    \\biggr\\rvert^{-1}\n",
    "    \\bigg\\vert_{x_{k-1} = f_k^{-1}(x_k)}\n",
    "    \\,. $$\n",
    "[more details on NF](http://akosiorek.github.io/ml/2018/04/03/norm_flows.html)\n",
    "\n",
    "also this [good VAE recap](https://www.borealisai.com/en/blog/tutorial-5-variational-auto-encoders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134009cf",
   "metadata": {},
   "source": [
    "if $x_k = f_k(x_{k-1})$ and $f_k$ is a diffeomorphism on the support, then\n",
    "(for $g=f_k^{-1}$)\n",
    "$$\n",
    "p_k(x_k)\n",
    "    = p_{k-1}(x_{k-1}) \\,\n",
    "    \\biggl\\lvert\n",
    "        \\det \\frac{\\partial x_k}{\\partial x_{k-1}}\n",
    "    \\biggr\\rvert^{-1}\n",
    "    \\bigg\\vert_{x_{k-1} = f_k^{-1}(x_k)}\n",
    "    \\,. $$\n",
    "with $\n",
    "    \\frac{\\partial x_k}{\\partial x_{k-1}}\n",
    "        \\equiv \\frac{\\partial x_k^\\top}{\\partial x_{k-1}}\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1ae97",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "280d8155",
   "metadata": {},
   "source": [
    "class modRepr(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = Sequential(\n",
    "            Conv2d(3, 32, 3, padding=1),\n",
    "            LeakyReLU(),\n",
    "            Conv2d(32, 64, 3, padding=1),\n",
    "            LeakyReLU(),\n",
    "            Conv2d(64, 64, 3, padding=0)\n",
    "        )\n",
    "        self.core = GRU(64*3*3, 128, num_layers=1, batch_first=False)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        x = input.div(255).sub_(0.5)\n",
    "        x = batchify(self.features, x, end=1)\n",
    "        s, hx = self.core(x.flatten(-3, -1), hx)\n",
    "        return s, hx\n",
    "\n",
    "class modDyn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = Embedding(5, 8)\n",
    "    \n",
    "        self.core = Sequential(\n",
    "            Linear(128+8, 256),\n",
    "            LeakyReLU(),\n",
    "            Linear(256, 256),\n",
    "        )\n",
    "\n",
    "        self.output = Sequential(\n",
    "            LeakyReLU(),\n",
    "            Linear(256, 128+1+5+1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, s, act):\n",
    "        x = self.core(torch.cat([\n",
    "            s, self.features(act)\n",
    "        ], dim=-1))\n",
    "    \n",
    "        s, rew, pol, val = self.output(x).split([128, 1, 5, 1], dim=-1)\n",
    "        \n",
    "        pol = F.log_softmax(pol, dim=-1)\n",
    "        return s, rew.squeeze(-1), pol, val.squeeze(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "895aa228",
   "metadata": {},
   "source": [
    "def play(env, ctrl, viewer=None):\n",
    "    obs, fin, act = env.reset(), False, env.action_space.sample()\n",
    "    while not fin:\n",
    "        if viewer is not None:\n",
    "            with torch.no_grad():\n",
    "                x = torch.tensor(obs).permute(2, 0, 1).div(255)\n",
    "                hat_x = dec(enc(x.unsqueeze(0)).sample()).mean\n",
    "                rec = hat_x[0].permute(1, 2, 0).mul(255).byte().squeeze(-1)\n",
    "            \n",
    "                act = torch.tensor([act])\n",
    "                xp1 = dec(dyn(enc(x.unsqueeze(0)).sample(), act).sample()).mean\n",
    "                nxt = xp1[0].permute(1, 2, 0).mul(255).byte().squeeze(-1)\n",
    "            \n",
    "            if isinstance(viewer, MultiViewer):\n",
    "                viewer['curr'].imshow(rec.numpy())\n",
    "                viewer['next'].imshow(nxt.numpy())\n",
    "            else:\n",
    "                viewer.imshow(rec.numpy())\n",
    "\n",
    "        if ctrl.action is not None:  # makes atari turn-based!\n",
    "            act = env.named_actions[env.KEYMAP[ctrl.action]]\n",
    "            ctrl.action = None\n",
    "\n",
    "            if not ctrl.dream:\n",
    "                obs, rew, fin, info = env.step(act)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if fin:  # pause on termination\n",
    "            ctrl.pause = True\n",
    "\n",
    "        # rendering and UI event loop\n",
    "        while render(env) > 0:\n",
    "            time.sleep(0.04)\n",
    "            if not ctrl.pause:\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bae907",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
